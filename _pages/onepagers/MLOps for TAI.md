---
permalink: /mlops-for-tai/
title: "MLOps for Trustworthy AI"
layout: single
author_profile: true
classes: wide
header:
  image: /assets/images/onepagers/mlops_for_tai.png
---

<html>
<body>

<!-- IMAGE -->
<p class="image" style="font-size:10.0px; text-align:right;"><img src="/assets/images/onepagers/mlops_for_tai.png" alt="MLOps_Image.png"><br>
Image by NVIDIA corporation</p>

<!-- ABSTRACT -->
<p style="color:red;">This is a red paragraph.</p>
<p class="notice--info"><span style="font-size:14.0px;">MLOps provides a framework to implement trustworthy AI and makes trustworthy AI realisable for industry players.</span></p>

<!-- PARAGRAPHS AND SUBTITLES -->
<h2 ><b>Setting</b></h2>
<p class="p">Emerging regulations call for high-level ethical guidelines for Trustworthy AI (TAI). This rises the need for a framework of related technical guidelines and workflows. Machine Learning Operations (MLOps) is a framework inspired by DevOps (development and operations) and encompasses a set of methods, best practices and tools that cover all stages from project setup over deployment to continuous operation. MLOps can naturally be extended to meet the requirements of TAI.</p>

<h2><b>Dimensions</b></h2>
<p class="p3"><span class="s1">The right level of </span><span class="s2">autonomy</span><span class="s1"> for the AI application and adequate control by humans can be addressed during the MLOps stages of model engineering, deployment, monitoring and maintenance.</span></p>

<p class="p3"><span class="s2">Fairness</span><span class="s1"> prevents unjust discrimination in AI use. It can be ensured by constraint enforcement and ongoing monitoring in the model engineering and monitoring stages.</span></p>

<p class="p3"><span class="s2">Privacy</span><span class="s1"> demands safeguards to sensitive data. During data and model engineering approaches can be applied to meet this demand. Data minimization, reduction of attack surfaces and differential privacy shall serve as examples.</span></p>

<p class="p3"><span class="s2">Reliability</span><span class="s1"> is attained when robustness can be assured for a variety of inputs and when the uncertainty of the outputs is correctly handled. During model engineering and evaluation approaches such as certified training, testing for adversarial attacks and formal verification can be used to enhance reliability. During deployment user adversarial actions must be considered and fast recovery should be possible.</span></p>

<p class="p3"><span class="s2">Security</span><span class="s1"> involves safeguarding the AI application against attacks. The deployment and monitoring stages can be made secure with traditional IT security methods.</span></p>

<p class="p3"><span class="s2">Transparency</span><span class="s1"> encompasses many concepts such as interpretability, Explainability and comprehensibility for different stakeholders, as well as result reproducibility and explainability. Throughout model evaluation, monitoring and maintenance, explainability methods and MLOps practices such as reproducibility and versioning promote transparency.</span></p>
<br>

<!-- REFERENCE -->
<h2><b>Reference</b></h2>
<p class="p3"><span class="s1">Yann Billeter, Philipp Denzel, Ricardo Chavarriaga, Oliver Forster, Frank-Peter Schilling, Stefan Brunner, Carmen Frischknecht-Gruber, Monika Reif, and Joanna Weng (2024). MLOps as Enabler of Trustworthy AI. ZHAW Digital Collection. Available at: <a href="https://digitalcollection.zhaw.ch/bitstream/11475/30443/3/2024_Billeter-etal_MLOps-for-Trustworthy-AI_SDS24.pdf"><span class="s3">Link</span></a></span></p>
<br>

<!-- RESOURCES -->
<h1 style="margin: 0.0px 0.0px 16.1px 0.0px; font: 24.0px Times; color: #012087; -webkit-text-stroke: #012087"><span class="s1"><b>Recommended Resources:</b></span></h1>
<table style="width:100%;align:center;">
<tr>
<td class="middle" align="left" style="font-size:140%;width:25%;vertical-align:top">
  <a href="ethics/assessment%20tool/ALTAI-The-Assessment-List-for-Trustwor/"><img src="Summary.png" alt="OCEANIS-Global AI Standards Repository" width="25%" border="10"><br><br>Transparency for Artificial Intelligence</a>
</td>
<td class="middle" align="left" style="font-size:140%;width:25%;vertical-align:top">
  <a href="ethics/assessment%20tool/ALTAI-The-Assessment-List-for-Trustwor/"><img src="Summary.png" alt="OCEANIS-Global AI Standards Repository" width="25%" border="10"><br><br>Transparency for Artificial Intelligence II</a>
</td>
<td class="middle" align="left" style="font-size:140%;width:25%;vertical-align:top">
  <a href="https://digitalcollection.zhaw.ch/bitstream/11475/30443/3/2024_Billeter-etal_MLOps-for-Trustworthy-AI_SDS24.pdf"><img src="Paper.png" alt="OCEANIS-Global AI Standards Repository" width="25%" border="10"><br><br>MLOps as Enabler of Trustworthy AI</a>
</td>
</tr>
</table>
<br>
</body>
</html>

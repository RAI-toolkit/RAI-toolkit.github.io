---
permalink: /mlops-for-tai/
title: "MLOps for Trustworthy AI"
layout: single
author_profile: true
classes: wide
header:
  image: /assets/images/onepagers/mlops_for_tai.png
---

<html>
<body>

<!-- IMAGE -->
<p class="image" style="font-size:10.0px; text-align:right;"><img src="/assets/images/onepagers/mlops_for_tai.png" alt="MLOps_Image.png"><br>
Image by NVIDIA corporation</p>

<!-- ABSTRACT -->
<p class="notice--info"><span style="font-size:14.0px;">MLOps provides a framework to implement trustworthy AI and makes trustworthy AI realisable for industry players.</span></p>

<!-- PARAGRAPHS AND SUBTITLES -->
<h2 ><b>Setting</b></h2>
<p class="p">Emerging regulations call for high-level ethical guidelines for Trustworthy AI (TAI). This rises the need for a framework of related technical guidelines and workflows. Machine Learning Operations (MLOps) is a framework inspired by DevOps (development and operations) and encompasses a set of methods, best practices and tools that cover all stages from project setup over deployment to continuous operation. MLOps can naturally be extended to meet the requirements of TAI.</p>

<h2><b>Dimensions</b></h2>
<p class="p">The right level of <span class="s2">autonomy</span> for the AI application and adequate control by humans can be addressed during the MLOps stages of model engineering, deployment, monitoring and maintenance.</p>

<p class="p"><span class="s2">Fairness</span> prevents unjust discrimination in AI use. It can be ensured by constraint enforcement and ongoing monitoring in the model engineering and monitoring stages.</p>

<p class="p"><span class="s2">Privacy</span>demands safeguards to sensitive data. During data and model engineering approaches can be applied to meet this demand. Data minimization, reduction of attack surfaces and differential privacy shall serve as examples.</p>

<p class="p"><span class="s2">Reliability</span> is attained when robustness can be assured for a variety of inputs and when the uncertainty of the outputs is correctly handled. During model engineering and evaluation approaches such as certified training, testing for adversarial attacks and formal verification can be used to enhance reliability. During deployment user adversarial actions must be considered and fast recovery should be possible.</p>

<p class="p"><span class="s2">Security</span> involves safeguarding the AI application against attacks. The deployment and monitoring stages can be made secure with traditional IT security methods.</p>

<p class="p"><span class="s2">Transparency</span> encompasses many concepts such as interpretability, Explainability and comprehensibility for different stakeholders, as well as result reproducibility and explainability. Throughout model evaluation, monitoring and maintenance, explainability methods and MLOps practices such as reproducibility and versioning promote transparency.</p>
<br>

<!-- REFERENCE -->
<h2><b>Reference</b></h2>
<p class="p"><span class="s1">Yann Billeter, Philipp Denzel, Ricardo Chavarriaga, Oliver Forster, Frank-Peter Schilling, Stefan Brunner, Carmen Frischknecht-Gruber, Monika Reif, and Joanna Weng (2024). MLOps as Enabler of Trustworthy AI. ZHAW Digital Collection. Available at: <a href="https://digitalcollection.zhaw.ch/bitstream/11475/30443/3/2024_Billeter-etal_MLOps-for-Trustworthy-AI_SDS24.pdf"><span class="s3">Link</span></a></span></p>
<br>

<!-- RESOURCES -->
<h1><b>Recommended Foll0w-Ups:</b></h1>
<br>

<h1><b>Recommended Resources:</b></h1>
<table style="width:100%;align:center;">
<tr>
<td class="middle" align="center" style="font-size:140%;width: 25%;vertical-align:top">
 	<a href="ethics/assessment%20tool/ALTAI-The-Assessment-List-for-Trustwor/"><img src="/assets/images/RAI_toolkit/Assess.png" alt="ALTAI - The Assessment List for Trustworthy Artificial Intelligence" width="200" border="10"><br><br>ALTAI - The Assessment List for Trustworthy Artificial Intelligence</a>
<td class="middle" align="center" style="font-size:140%;width: 25%;vertical-align:top">
 	<a href="ethics/assessment%20tool/ALTAI-The-Assessment-List-for-Trustwor/"><img src="/assets/images/RAI_toolkit/Assess.png" alt="ALTAI - The Assessment List for Trustworthy Artificial Intelligence" width="200" border="10"><br><br>ALTAI - The Assessment List for Trustworthy Artificial Intelligence</a>
</td>
<td class="middle" align="center" style="font-size:140%;width: 25%;vertical-align:top">
 	<a href="ethics/assessment%20tool/ALTAI-The-Assessment-List-for-Trustwor/"><img src="/assets/images/RAI_toolkit/Assess.png" alt="ALTAI - The Assessment List for Trustworthy Artificial Intelligence" width="200" border="10"><br><br>ALTAI - The Assessment List for Trustworthy Artificial Intelligence</a>
</td>
<td class="middle" align="center" style="font-size:140%;width: 25%;vertical-align:top">
 	<a href="ethics/assessment%20tool/ALTAI-The-Assessment-List-for-Trustwor/"><img src="/assets/images/RAI_toolkit/Assess.png" alt="ALTAI - The Assessment List for Trustworthy Artificial Intelligence" width="200" border="10"><br><br>ALTAI - The Assessment List for Trustworthy Artificial Intelligence</a>
</td>
